{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TF-IDF\n",
    "## TF-IDF stands for term-frequency document inverse frequency. It is a very common algorithm to convert text into a meaningful sequence of numbers. It becomes very important to evaluate the most meaningful words in a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sample document list\n",
    "mydocList = [\"this car got the excellence award\",\\\n",
    "         \"good car gives good mileage\",\\\n",
    "         \"this car is very expensive\",\\\n",
    "         \"the company is growing with very high production\",\\\n",
    "         \"this company is financially good\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf is made up of two parts, term frequency and Inverse data frequency. Term frequency gives us the frequency of each word in each document of the corpus\n",
    "\n",
    "#### tf ->\n",
    "\n",
    "$$\n",
    "tf_i,j =  n_i,j/(\\Sigma_k n_i,j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tokens = list(map(lambda x:set(x.split(\" \")),mydocList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'award', 'car', 'excellence', 'got', 'the', 'this'},\n",
       " {'car', 'gives', 'good', 'mileage'},\n",
       " {'car', 'expensive', 'is', 'this', 'very'},\n",
       " {'company', 'growing', 'high', 'is', 'production', 'the', 'very', 'with'},\n",
       " {'company', 'financially', 'good', 'is', 'this'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "car\n",
      "got\n",
      "the\n",
      "excellence\n",
      "award\n",
      "dict_items([('award', 1), ('this', 1), ('the', 1), ('car', 1), ('excellence', 1), ('got', 1)])\n",
      "good\n",
      "car\n",
      "gives\n",
      "good\n",
      "mileage\n",
      "dict_items([('mileage', 1), ('gives', 1), ('good', 2), ('car', 1)])\n",
      "this\n",
      "car\n",
      "is\n",
      "very\n",
      "expensive\n",
      "dict_items([('this', 1), ('expensive', 1), ('is', 1), ('very', 1), ('car', 1)])\n",
      "the\n",
      "company\n",
      "is\n",
      "growing\n",
      "with\n",
      "very\n",
      "high\n",
      "production\n",
      "dict_items([('is', 1), ('production', 1), ('with', 1), ('the', 1), ('company', 1), ('growing', 1), ('very', 1), ('high', 1)])\n",
      "this\n",
      "company\n",
      "is\n",
      "financially\n",
      "good\n",
      "dict_items([('this', 1), ('company', 1), ('is', 1), ('good', 1), ('financially', 1)])\n"
     ]
    }
   ],
   "source": [
    "for doc in mydocList:\n",
    "    tf = Counter()\n",
    "    for word in doc.split():\n",
    "        print(word)\n",
    "        tf[word] +=1\n",
    "    print (tf.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lexicon(corpus):\n",
    "    lexicon = set()\n",
    "    for doc in corpus:\n",
    "        lexicon.update([word for word in doc.split()])\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf(term, document):\n",
    "    return freq(term, document)\n",
    "\n",
    "def freq(term, document):\n",
    "    return document.split().count(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = build_lexicon(mydocList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'award',\n",
       " 'car',\n",
       " 'company',\n",
       " 'excellence',\n",
       " 'expensive',\n",
       " 'financially',\n",
       " 'gives',\n",
       " 'good',\n",
       " 'got',\n",
       " 'growing',\n",
       " 'high',\n",
       " 'is',\n",
       " 'mileage',\n",
       " 'production',\n",
       " 'the',\n",
       " 'this',\n",
       " 'very',\n",
       " 'with'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_term_matrix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydocList.index(\"this car got the excellence award\")+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary vector is [very, expensive, company, high, financially, gives, got, car, is, award, production, good, growing, this, the, with, mileage, excellence]\n",
      "The doc is \"this car got the excellence award\"\n",
      "The tf vector for Document 1 is [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1]\n",
      "The doc is \"good car gives good mileage\"\n",
      "The tf vector for Document 2 is [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0]\n",
      "The doc is \"this car is very expensive\"\n",
      "The tf vector for Document 3 is [1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "The doc is \"the company is growing with very high production\"\n",
      "The tf vector for Document 4 is [1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0]\n",
      "The doc is \"this company is financially good\"\n",
      "The tf vector for Document 5 is [0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "All combined, here is our master document term matrix: \n",
      "[[0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0], [1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0], [0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print ('Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']')\n",
    "for doc in mydocList:\n",
    "    print ('The doc is \"' + doc + '\"')\n",
    "    tf_vector = [tf(word, doc) for word in vocabulary]\n",
    "    tf_vector_string = ', '.join(format(freq, 'd') for freq in tf_vector)\n",
    "    print ('The tf vector for Document %d is [%s]' % ((mydocList.index(doc)+1), tf_vector_string))\n",
    "    doc_term_matrix.append(tf_vector)\n",
    "    \n",
    "    # here's a test: why did I wrap mydoclist.index(doc)+1 in parens?  it returns an int...\n",
    "    # try it!  type(mydoclist.index(doc) + 1)\n",
    "\n",
    "print ('All combined, here is our master document term matrix: ')\n",
    "print (doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def l2_normalizer(vec):\n",
    "    denom = np.sum([el**2 for el in vec])\n",
    "    return [(el / math.sqrt(denom)) for el in vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A regular old document term matrix: \n",
      "[[0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1]\n",
      " [0 0 0 0 0 1 0 1 0 0 0 2 0 0 0 0 1 0]\n",
      " [1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 1 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0]\n",
      " [0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0]]\n",
      "\n",
      "A document term matrix with row-wise L2 norms of 1:\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.40824829  0.40824829  0.          0.40824829  0.          0.          0.\n",
      "   0.40824829  0.40824829  0.          0.          0.40824829]\n",
      " [ 0.          0.          0.          0.          0.          0.37796447\n",
      "   0.          0.37796447  0.          0.          0.          0.75592895\n",
      "   0.          0.          0.          0.          0.37796447  0.        ]\n",
      " [ 0.4472136   0.4472136   0.          0.          0.          0.          0.\n",
      "   0.4472136   0.4472136   0.          0.          0.          0.\n",
      "   0.4472136   0.          0.          0.          0.        ]\n",
      " [ 0.35355339  0.          0.35355339  0.35355339  0.          0.          0.\n",
      "   0.          0.35355339  0.          0.35355339  0.          0.35355339\n",
      "   0.          0.35355339  0.35355339  0.          0.        ]\n",
      " [ 0.          0.          0.4472136   0.          0.4472136   0.          0.\n",
      "   0.          0.4472136   0.          0.          0.4472136   0.\n",
      "   0.4472136   0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "doc_term_matrix_l2 = []\n",
    "for vec in doc_term_matrix:\n",
    "    doc_term_matrix_l2.append(l2_normalizer(vec))\n",
    "\n",
    "print ('A regular old document term matrix: ' )\n",
    "print (np.matrix(doc_term_matrix))\n",
    "print ('\\nA document term matrix with row-wise L2 norms of 1:')\n",
    "print (np.matrix(doc_term_matrix_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Calculate idf\n",
    "def numDocsContaining(word, doclist):\n",
    "    doccount = 0\n",
    "    for doc in doclist:\n",
    "        if freq(word, doc) > 0:\n",
    "            doccount +=1\n",
    "    return doccount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idf(word, doclist):\n",
    "    n_samples = len(doclist)\n",
    "    df = numDocsContaining(word, doclist)\n",
    "    return np.log(n_samples / 1+df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_idf_vector = [idf(word, mydocList) for word in vocabulary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9459101490553132,\n",
       " 1.791759469228055,\n",
       " 1.9459101490553132,\n",
       " 1.791759469228055,\n",
       " 1.791759469228055,\n",
       " 1.791759469228055,\n",
       " 1.791759469228055,\n",
       " 2.0794415416798357,\n",
       " 2.0794415416798357,\n",
       " 1.791759469228055,\n",
       " 1.791759469228055,\n",
       " 1.9459101490553132,\n",
       " 1.791759469228055,\n",
       " 2.0794415416798357,\n",
       " 1.9459101490553132,\n",
       " 1.791759469228055,\n",
       " 1.791759469228055,\n",
       " 1.791759469228055]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_idf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((len(my_idf_vector),len(my_idf_vector)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_idf_matrix(idf_vector):\n",
    "    idf_mat = np.zeros((len(idf_vector), len(idf_vector)))\n",
    "    np.fill_diagonal(idf_mat, idf_vector)\n",
    "    return idf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_idf_matrix = build_idf_matrix(my_idf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_term_matrix_tfidf = []\n",
    "\n",
    "#performing tf-idf matrix multiplication\n",
    "for tf_vector in doc_term_matrix:\n",
    "    doc_term_matrix_tfidf.append(np.dot(tf_vector, my_idf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.79175947,  2.07944154,  0.        ,  1.79175947,\n",
       "         0.        ,  0.        ,  0.        ,  2.07944154,  1.94591015,\n",
       "         0.        ,  0.        ,  1.79175947]),\n",
       " array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.79175947,  0.        ,  2.07944154,  0.        ,  0.        ,\n",
       "         0.        ,  3.8918203 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.79175947,  0.        ]),\n",
       " array([ 1.94591015,  1.79175947,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  2.07944154,  2.07944154,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  2.07944154,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ]),\n",
       " array([ 1.94591015,  0.        ,  1.94591015,  1.79175947,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  2.07944154,  0.        ,\n",
       "         1.79175947,  0.        ,  1.79175947,  0.        ,  1.94591015,\n",
       "         1.79175947,  0.        ,  0.        ]),\n",
       " array([ 0.        ,  0.        ,  1.94591015,  0.        ,  1.79175947,\n",
       "         0.        ,  0.        ,  0.        ,  2.07944154,  0.        ,\n",
       "         0.        ,  1.94591015,  0.        ,  2.07944154,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_term_matrix_tfidf_l2 = []\n",
    "for tf_vector in doc_term_matrix_tfidf:\n",
    "    doc_term_matrix_tfidf_l2.append(l2_normalizer(tf_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.38143331669205544,\n",
       "  0.44267564800531067,\n",
       "  0.0,\n",
       "  0.38143331669205544,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.44267564800531067,\n",
       "  0.41424921976758283,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.38143331669205544],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.35213084473745043,\n",
       "  0.0,\n",
       "  0.4086684174016596,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.76485152872136042,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.35213084473745043,\n",
       "  0.0],\n",
       " [0.43545416953101851,\n",
       "  0.40095845743485192,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.46533571452931172,\n",
       "  0.46533571452931172,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.46533571452931172,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.36434015033694023,\n",
       "  0.0,\n",
       "  0.36434015033694023,\n",
       "  0.33547793288559974,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.38934174030610619,\n",
       "  0.0,\n",
       "  0.33547793288559974,\n",
       "  0.0,\n",
       "  0.33547793288559974,\n",
       "  0.0,\n",
       "  0.36434015033694023,\n",
       "  0.33547793288559974,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.44143575738829566,\n",
       "  0.0,\n",
       "  0.40646619718814886,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.47172776828455232,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.44143575738829566,\n",
       "  0.0,\n",
       "  0.47172776828455232,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix_tfidf_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ct = np.asarray(doc_term_matrix_tfidf_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.38143332,  0.44267565,  0.        ,  0.38143332,\n",
       "         0.        ,  0.        ,  0.        ,  0.44267565,  0.41424922,\n",
       "         0.        ,  0.        ,  0.38143332],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.35213084,  0.        ,  0.40866842,  0.        ,  0.        ,\n",
       "         0.        ,  0.76485153,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.35213084,  0.        ],\n",
       "       [ 0.43545417,  0.40095846,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.46533571,  0.46533571,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.46533571,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.36434015,  0.        ,  0.36434015,  0.33547793,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.38934174,  0.        ,\n",
       "         0.33547793,  0.        ,  0.33547793,  0.        ,  0.36434015,\n",
       "         0.33547793,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.44143576,  0.        ,  0.4064662 ,\n",
       "         0.        ,  0.        ,  0.        ,  0.47172777,  0.        ,\n",
       "         0.        ,  0.44143576,  0.        ,  0.47172777,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class tfidf:\n",
    "    def __init__(self,docList):\n",
    "        self.docList = docList\n",
    "    def build_lexicon(corpus):\n",
    "        lexicon = set()\n",
    "        for doc in corpus:\n",
    "            lexicon.update([word for word in doc.split()])\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

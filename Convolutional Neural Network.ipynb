{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad(X,pad):\n",
    "    \"\"\"\n",
    "    X is an array of shape(m,n_H,n_W,n_C) \n",
    "    where m =  no of images\n",
    "    n_H = height of image\n",
    "    n_W = width of image\n",
    "    n_C = no of channels\n",
    "    padding adds an equal amount of pad at the egdes of the image across all channels\n",
    "    \"\"\"\n",
    "    X_pad = X_pad = np.pad(X,((0,0),(pad,pad),(pad,pad),(0,0)),'constant',constant_values = 0)\n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.randn(4, 3, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.62434536, -0.61175641],\n",
       "         [-0.52817175, -1.07296862],\n",
       "         [ 0.86540763, -2.3015387 ]],\n",
       "\n",
       "        [[ 1.74481176, -0.7612069 ],\n",
       "         [ 0.3190391 , -0.24937038],\n",
       "         [ 1.46210794, -2.06014071]],\n",
       "\n",
       "        [[-0.3224172 , -0.38405435],\n",
       "         [ 1.13376944, -1.09989127],\n",
       "         [-0.17242821, -0.87785842]]],\n",
       "\n",
       "\n",
       "       [[[ 0.04221375,  0.58281521],\n",
       "         [-1.10061918,  1.14472371],\n",
       "         [ 0.90159072,  0.50249434]],\n",
       "\n",
       "        [[ 0.90085595, -0.68372786],\n",
       "         [-0.12289023, -0.93576943],\n",
       "         [-0.26788808,  0.53035547]],\n",
       "\n",
       "        [[-0.69166075, -0.39675353],\n",
       "         [-0.6871727 , -0.84520564],\n",
       "         [-0.67124613, -0.0126646 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.11731035,  0.2344157 ],\n",
       "         [ 1.65980218,  0.74204416],\n",
       "         [-0.19183555, -0.88762896]],\n",
       "\n",
       "        [[-0.74715829,  1.6924546 ],\n",
       "         [ 0.05080775, -0.63699565],\n",
       "         [ 0.19091548,  2.10025514]],\n",
       "\n",
       "        [[ 0.12015895,  0.61720311],\n",
       "         [ 0.30017032, -0.35224985],\n",
       "         [-1.1425182 , -0.34934272]]],\n",
       "\n",
       "\n",
       "       [[[-0.20889423,  0.58662319],\n",
       "         [ 0.83898341,  0.93110208],\n",
       "         [ 0.28558733,  0.88514116]],\n",
       "\n",
       "        [[-0.75439794,  1.25286816],\n",
       "         [ 0.51292982, -0.29809284],\n",
       "         [ 0.48851815, -0.07557171]],\n",
       "\n",
       "        [[ 1.13162939,  1.51981682],\n",
       "         [ 2.18557541, -1.39649634],\n",
       "         [-1.44411381, -0.50446586]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [ 1.62434536, -0.61175641],\n",
       "         [-0.52817175, -1.07296862],\n",
       "         [ 0.86540763, -2.3015387 ],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [ 1.74481176, -0.7612069 ],\n",
       "         [ 0.3190391 , -0.24937038],\n",
       "         [ 1.46210794, -2.06014071],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [-0.3224172 , -0.38405435],\n",
       "         [ 1.13376944, -1.09989127],\n",
       "         [-0.17242821, -0.87785842],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [ 0.04221375,  0.58281521],\n",
       "         [-1.10061918,  1.14472371],\n",
       "         [ 0.90159072,  0.50249434],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [ 0.90085595, -0.68372786],\n",
       "         [-0.12289023, -0.93576943],\n",
       "         [-0.26788808,  0.53035547],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [-0.69166075, -0.39675353],\n",
       "         [-0.6871727 , -0.84520564],\n",
       "         [-0.67124613, -0.0126646 ],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [-1.11731035,  0.2344157 ],\n",
       "         [ 1.65980218,  0.74204416],\n",
       "         [-0.19183555, -0.88762896],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [-0.74715829,  1.6924546 ],\n",
       "         [ 0.05080775, -0.63699565],\n",
       "         [ 0.19091548,  2.10025514],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [ 0.12015895,  0.61720311],\n",
       "         [ 0.30017032, -0.35224985],\n",
       "         [-1.1425182 , -0.34934272],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [-0.20889423,  0.58662319],\n",
       "         [ 0.83898341,  0.93110208],\n",
       "         [ 0.28558733,  0.88514116],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [-0.75439794,  1.25286816],\n",
       "         [ 0.51292982, -0.29809284],\n",
       "         [ 0.48851815, -0.07557171],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [ 1.13162939,  1.51981682],\n",
       "         [ 2.18557541, -1.39649634],\n",
       "         [-1.44411381, -0.50446586],\n",
       "         [ 0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad(x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: conv_single_step\n",
    "\n",
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
    "    of the previous layer.\n",
    "    \n",
    "    Arguments:\n",
    "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
    "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
    "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
    "    \n",
    "    Returns:\n",
    "    Z -- a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    # Element-wise product between a_slice and W. Do not add the bias yet.\n",
    "    s = np.multiply(a_slice_prev,W) + b\n",
    "    # Sum over all entries of the volume s.\n",
    "    Z = np.sum(s)\n",
    "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_slice_prev = np.random.randn(4, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.16003707,  0.87616892,  0.31563495],\n",
       "        [-2.02220122, -0.30620401,  0.82797464],\n",
       "        [ 0.23009474,  0.76201118, -0.22232814],\n",
       "        [-0.20075807,  0.18656139,  0.41005165]],\n",
       "\n",
       "       [[ 0.19829972,  0.11900865, -0.67066229],\n",
       "        [ 0.37756379,  0.12182127,  1.12948391],\n",
       "        [ 1.19891788,  0.18515642, -0.37528495],\n",
       "        [-0.63873041,  0.42349435,  0.07734007]],\n",
       "\n",
       "       [[-0.34385368,  0.04359686, -0.62000084],\n",
       "        [ 0.69803203, -0.44712856,  1.2245077 ],\n",
       "        [ 0.40349164,  0.59357852, -1.09491185],\n",
       "        [ 0.16938243,  0.74055645, -0.9537006 ]],\n",
       "\n",
       "       [[-0.26621851,  0.03261455, -1.37311732],\n",
       "        [ 0.31515939,  0.84616065, -0.85951594],\n",
       "        [ 0.35054598, -1.31228341, -0.03869551],\n",
       "        [-1.61577235,  1.12141771,  0.40890054]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_slice_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-2.02220122, -0.30620401,  0.82797464],\n",
       "        [ 0.23009474,  0.76201118, -0.22232814],\n",
       "        [-0.20075807,  0.18656139,  0.41005165]],\n",
       "\n",
       "       [[ 0.37756379,  0.12182127,  1.12948391],\n",
       "        [ 1.19891788,  0.18515642, -0.37528495],\n",
       "        [-0.63873041,  0.42349435,  0.07734007]],\n",
       "\n",
       "       [[ 0.69803203, -0.44712856,  1.2245077 ],\n",
       "        [ 0.40349164,  0.59357852, -1.09491185],\n",
       "        [ 0.16938243,  0.74055645, -0.9537006 ]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_slice_prev[0:3,1:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(n_H,n_W,n_C) = a_slice_prev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a convolution function\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
    "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
    "        \n",
    "    Returns:\n",
    "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of values needed for the conv_backward() function\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Retrieve dimensions from A_prev's shape (≈1 line)  \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape (≈1 line)\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "\n",
    "    # Retrieve information from \"hparameters\" (≈2 lines)\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    \n",
    "    # Compute the dimensions of the CONV output volume using the formula given above. Hint: use int() to floor. (≈2 lines)\n",
    "    n_H = int((n_H_prev - f + 2 * pad) / stride) + 1\n",
    "    n_W = int((n_W_prev - f + 2 * pad) / stride) + 1\n",
    "    \n",
    "    # Initialize the output volume Z with zeros. (≈1 line)\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):                                 # loop over the batch of training examples\n",
    "        a_prev_pad = A_prev_pad[i]                     # Select ith training example's padded activation\n",
    "        for h in range(n_H):                           # loop over vertical axis of the output volume\n",
    "            for w in range(n_W):                       # loop over horizontal axis of the output volume\n",
    "                for c in range(n_C):                   # loop over channels (= #filters) of the output volume\n",
    "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[...,c], b[...,c])\n",
    "                                        \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Making sure your output shape is correct\n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
